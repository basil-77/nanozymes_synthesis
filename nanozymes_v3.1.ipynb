{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18bc78e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec6da1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthesis_scheme():\n",
    "    \n",
    "    def _init_(self):\n",
    "        c1 = 0\n",
    "        c2 = 0\n",
    "        cad = 0\n",
    "        heat = 0\n",
    "        autoclave = 0\n",
    "        r1 = 'None'\n",
    "        r2 = 'None'\n",
    "        solvent = 'None'\n",
    "        add_to_solvent = 'None'\n",
    "        return\n",
    "    \n",
    "    def __str__(self):\n",
    "        out = 'R1: ' + str(self.r1) + '\\n' + \\\n",
    "            'C1: ' + str(self.c1) + '\\n' + \\\n",
    "            'R2: ' + str(self.r2) + '\\n' + \\\n",
    "            'C2: ' + str(self.c2) + '\\n' + \\\n",
    "            'Solvent: ' + self.solvent + '\\n' + \\\n",
    "            'Add to solvent: ' + self.add_to_solvent + '\\n' + \\\n",
    "            'Cad: ' + str(self.cad) + '\\n' + \\\n",
    "            'Heat: ' + str(self.heat) + '\\n' + \\\n",
    "            'Autoclave: ' + str(int(self.autoclave)) + '\\n'\n",
    "            \n",
    "        return out\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba83e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nanozymes_synthesis():\n",
    "    \n",
    "    def _init_(self):\n",
    "        return\n",
    "        \n",
    "    \n",
    "    def load(self,\n",
    "             sourse_data, #='nanozymes.xlsx',\n",
    "             target_data, #='nanozymes_add.xlsx',\n",
    "             voc_formulas, #='nanozymes_formulas.xlsx',\n",
    "             voc_reactions, #='reaction_types.xlsx',\n",
    "             voc_reagents,\n",
    "             voc_solvents,\n",
    "             voc_solvents_add\n",
    "            ):\n",
    "        \n",
    "        self.df_main = pd.read_excel(sourse_data, index_col=0, usecols=['index',\n",
    "                                                                        'formula',\n",
    "                                                                        'length, nm',\n",
    "                                                                        'width, nm',\n",
    "                                                                        'depth, nm',\n",
    "                                                                        'Km, mM'])\n",
    "        #self.df_rtypes = pd.read_excel(voc_reactions, index_col=0)\n",
    "        self.df_formulas = pd.read_excel(voc_formulas, index_col=0)\n",
    "        self.df_add = pd.read_excel(target_data, usecols=['Индекс',\n",
    "                                                            'R1',\n",
    "                                                            'R2',\n",
    "                                                            'solvent',\n",
    "                                                            'C1',\n",
    "                                                            'C2',\n",
    "                                                            'add to solvent',\n",
    "                                                            'Сad',\n",
    "                                                            'heat',\n",
    "                                                            'autoclave'])\n",
    "        self.df_rs = pd.read_excel(voc_reagents, index_col=None)\n",
    "        self.df_solvents = pd.read_excel(voc_solvents, index_col=None)\n",
    "        self.df_solvents_add = pd.read_excel(voc_solvents_add, index_col=None)\n",
    "        \n",
    "        return\n",
    "        \n",
    "        \n",
    "    def _prepare_main(self, df):\n",
    "    \n",
    "        df['length, nm'].fillna(0, inplace=True)\n",
    "        df['width, nm'].fillna(0, inplace=True)\n",
    "        df['depth, nm'].fillna(0, inplace=True)\n",
    "    \n",
    "        df['Km, mM'] = pd.to_numeric(df['Km, mM'], errors='coerce')   \n",
    "        df['Km, mM'].fillna(0, inplace=True)\n",
    "\n",
    "        #scaling\n",
    "        #df['Vmax, mM/s'] = df['Vmax, mM/s'] * 1000.\n",
    "        #df['Ccat(mg/mL)'] = df['Ccat(mg/mL)'] * 1000.        \n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def preprocessing(self):\n",
    "        \n",
    "        self._prepare_main(self.df_main)\n",
    "        self.build_merged_data()\n",
    "                \n",
    "        return\n",
    "        \n",
    "    def build_merged_data(self):\n",
    "        \n",
    "        df_main_merged = self.df_main.merge(self.df_formulas, left_on='formula', right_on='formula', how='left')\n",
    "        \n",
    "        df_merged = self.df_add.merge(self.df_rs, left_on='R1', right_on='formula', how='inner', suffixes=(None,'_r1'))\n",
    "        \n",
    "        df_merged = df_merged.merge(self.df_rs, left_on='R2', right_on='formula', how='inner', suffixes=(None,'_r2'))\n",
    "        df_merged = df_merged.merge(self.df_solvents, left_on='solvent', right_on='formula', how='inner', suffixes=(None,'_solvent'))\n",
    "        df_merged = df_merged.merge(self.df_solvents_add, left_on='add to solvent', right_on='formula', how='inner', suffixes=(None,'_add_to_solvent'))\n",
    "        \n",
    "        df_merged.set_index('Индекс', inplace=True)\n",
    "        df_merged = df_merged.drop(columns=['R1','R2', 'solvent', 'add to solvent',\n",
    "                                            'formula', 'dec_ord', 'r_all', 'formula_r2', 'dec_ord_r2', 'r_all_r2',\n",
    "                                            'formula_solvent', 'dec_ord_solvent','r_all_solvent',\n",
    "                                            'formula_add_to_solvent','dec_ord_add_to_solvent','r_all_add_to_solvent',\n",
    "                                            #'Индекс'\n",
    "                                           ])\n",
    "        df_main_merged.to_excel('main_merged.xlsx')\n",
    "        df_merged.to_excel('merged.xlsx')\n",
    "        self.df_all = df_main_merged.merge(df_merged, left_index=True, right_index=True, how='inner')\n",
    "        #self.df_all.to_excel('temp.xlsx')\n",
    "        #self.df_dummies = pd.get_dummies(df_all)\n",
    "\n",
    "        self.columns_source = [\n",
    "                           'length, nm', 'width, nm', 'depth, nm',\n",
    "                           'formula_0', 'formula_1', 'formula_2', 'formula_3', 'formula_4',\n",
    "                           'formula_5', 'formula_6', 'formula_7', 'formula_8'\n",
    "                         ]\n",
    "        self.columns_target = ['C1','C2', 'Сad', 'heat', 'autoclave',\n",
    "                          'r_0', 'r_1', 'r_2', 'r_3', 'r_4', 'r_5', 'r_6',\n",
    "                          'r_0_r2', 'r_1_r2', 'r_2_r2', 'r_3_r2', 'r_4_r2', 'r_5_r2',\n",
    "                          'r_6_r2', 'r_0_solvent', 'r_1_solvent', 'r_2_solvent',\n",
    "                          'r_3_solvent', 'r_4_solvent',\n",
    "                          'r_0_add_to_solvent', 'r_1_add_to_solvent', 'r_2_add_to_solvent',\n",
    "                          'r_3_add_to_solvent', 'r_4_add_to_solvent', 'r_5_add_to_solvent'\n",
    "                         ]\n",
    "               \n",
    "        return\n",
    "\n",
    "    def model_linear(self, inp_len, out_len):\n",
    "\n",
    "        input = Input(inp_len)\n",
    "        inner_1 = Dense(out_len)(input)\n",
    "        inner_1 = Activation('elu')(inner_1)\n",
    "        inner_2 = Dense(out_len)(inner_1)\n",
    "        inner_2 = Activation('elu')(inner_2)\n",
    "        inner_3 = Dense(out_len)(inner_2)\n",
    "        inner_3 = Activation('elu')(inner_3)\n",
    "        inner_4 = Dense(inp_len*3)(inner_3)\n",
    "        inner_4 = Activation('elu')(inner_4)        \n",
    "        inner_5 = Dense(inp_len*2)(inner_4)\n",
    "        inner_5 = Activation('elu')(inner_5)        \n",
    "        out = Dense(out_len)(inner_3)\n",
    "        out = Activation('relu')(out)\n",
    "\n",
    "        model = Model(input, out)\n",
    "        model.summary()\n",
    "\n",
    "        return model    \n",
    "\n",
    "    def plot_history(self):\n",
    "        \n",
    "        plt.plot(self.history.history['loss'], label='train loss')\n",
    "        plt.plot(self.history.history['val_loss'], label='val loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def train(self, lr, epochs):\n",
    "        \n",
    "        inp_len = len(self.columns_source)\n",
    "        out_len = len(self.columns_target)\n",
    "        \n",
    "        df_input = self.df_all[self.columns_source].to_numpy()\n",
    "        df_target = self.df_all[self.columns_target].to_numpy()\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(df_input, df_target,\n",
    "                                                    test_size=0.2, random_state=42)\n",
    "        self.X_train = X_train\n",
    "        \n",
    "        self.X_scaler = MinMaxScaler()\n",
    "\n",
    "        X_train_scaled = self.X_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.X_scaler.transform(X_test)\n",
    "\n",
    "        \n",
    "        joblib.dump(self.X_scaler, 'x_scaler')\n",
    "\n",
    "        self.model = self.model_linear(inp_len, out_len)\n",
    "        self.model.compile(optimizer=Adamax(learning_rate=lr), loss='mae')\n",
    "        \n",
    "        reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                        factor=0.1,\n",
    "                                        patience=5)\n",
    "        \n",
    "        self.history = self.model.fit(X_train_scaled, Y_train,\n",
    "                                       epochs=epochs,\n",
    "                                       #callbacks=[reduce_lr],\n",
    "                                       validation_data=(X_test_scaled, Y_test),\n",
    "                                       batch_size=1)\n",
    "        \n",
    "        \n",
    "        return self.history\n",
    "    \n",
    "    def predict(self, data):\n",
    "        \n",
    "        data_scaled = self.X_scaler.transform(data)\n",
    "        out = self.model.predict(data_scaled)\n",
    "\n",
    "        out = out[0]\n",
    "        self.out = out\n",
    "        \n",
    "        res = synthesis_scheme()        \n",
    "        res.c1 = out[0]\n",
    "        res.c2 = out[1]\n",
    "        res.cad = out[2]\n",
    "        res.heat = out[3]       \n",
    "        res.autoclave = 1 if out[4]>=0.5 else 0\n",
    "        res.r1 = self._get_rname(out[5:12])\n",
    "        res.r2 = self._get_rname(out[12:19])\n",
    "        res.solvent = self._get_solventsname(out[19:24])\n",
    "        res.add_to_solvent = self._get_solventsaddname(out[24:30])\n",
    "               \n",
    "        return res\n",
    "    \n",
    "    def _get_rname(self, data_bin):\n",
    "        \n",
    "        data_bin[data_bin>=0.5] = 1\n",
    "        data_bin[data_bin<0.5] = 0\n",
    "        data_bin = data_bin.astype(int)\n",
    "        data_bin = ''.join(data_bin.astype(str))\n",
    "        res = self.df_rs[self.df_rs.r_all == int(data_bin)].to_numpy()\n",
    "        res = 'None' if res.shape[0]==0 else res[0,0]\n",
    "        return res\n",
    "\n",
    "    def _get_solventsname(self, data_bin):\n",
    "        \n",
    "        data_bin[data_bin>=0.5] = 1\n",
    "        data_bin[data_bin<0.5] = 0\n",
    "        data_bin = data_bin.astype(int)\n",
    "        data_bin = ''.join(data_bin.astype(str))\n",
    "        res = self.df_solvents[self.df_solvents.r_all == int(data_bin)].to_numpy()\n",
    "        res = 'None' if res.shape[0]==0 else res[0,0]\n",
    "        return res    \n",
    "\n",
    "    def _get_solventsaddname(self, data_bin):\n",
    "        \n",
    "        data_bin[data_bin>=0.5] = 1\n",
    "        data_bin[data_bin<0.5] = 0\n",
    "        data_bin = data_bin.astype(int)\n",
    "        data_bin = ''.join(data_bin.astype(str))\n",
    "        res = self.df_solvents_add[self.df_solvents_add.r_all == int(data_bin)].to_numpy()\n",
    "        res = 'None' if res.shape[0]==0 else res[0,0]\n",
    "        return res    \n",
    "    \n",
    "    \n",
    "    def _get_nanozymesmname(self, data_bin):\n",
    "        \n",
    "        data_bin[data_bin>=0.5] = 1\n",
    "        data_bin[data_bin<0.5] = 0\n",
    "        data_bin = data_bin.astype(int)\n",
    "        data_bin = ''.join(data_bin.astype(str))\n",
    "        res = self.df_formulas[self.df_formulas.r_all == int(data_bin)].to_numpy()\n",
    "        res = 'None' if res.shape[0]==0 else res[0,0]\n",
    "        return res\n",
    "\n",
    "    def _get_rtypesname(self, data_bin):\n",
    "        \n",
    "        data_bin[data_bin>=0.5] = 1\n",
    "        data_bin[data_bin<0.5] = 0\n",
    "        data_bin = data_bin.astype(int)\n",
    "        data_bin = ''.join(data_bin.astype(str))\n",
    "        res = self.df_rtypes[self.df_rtypes.r_all == int(data_bin)].to_numpy()\n",
    "        res = 'None' if res.shape[0]==0 else res[0,0]\n",
    "        return res\n",
    "\n",
    "    def encode_nanozymes(self, formula):\n",
    "        \n",
    "        res = np.array([\n",
    "                        (self.df_formulas[self.df_formulas.index == formula].to_numpy())[0,2],\n",
    "                        (self.df_formulas[self.df_formulas.index == formula].to_numpy())[0,3],\n",
    "                        (self.df_formulas[self.df_formulas.index == formula].to_numpy())[0,4],\n",
    "                        (self.df_formulas[self.df_formulas.index == formula].to_numpy())[0,5],\n",
    "                        (self.df_formulas[self.df_formulas.index == formula].to_numpy())[0,6],\n",
    "                        (self.df_formulas[self.df_formulas.index == formula].to_numpy())[0,7],\n",
    "                        (self.df_formulas[self.df_formulas.index == formula].to_numpy())[0,8],\n",
    "                        (self.df_formulas[self.df_formulas.index == formula].to_numpy())[0,9],\n",
    "                        (self.df_formulas[self.df_formulas.index == formula].to_numpy())[0,10]\n",
    "                     ])\n",
    "        return res    \n",
    "    \n",
    "    def model_save(self, model_path):\n",
    "        \n",
    "        self.model.save(model_path)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def model_load(self, model_path, scaler_file):\n",
    "        \n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        self.X_scaler = joblib.load(scaler_file)\n",
    "        \n",
    "        return\n",
    "    \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0cbf6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 12)]              0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 30)                390       \n",
      "                                                                 \n",
      " activation_48 (Activation)  (None, 30)                0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " activation_49 (Activation)  (None, 30)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " activation_50 (Activation)  (None, 30)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " activation_53 (Activation)  (None, 30)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,180\n",
      "Trainable params: 3,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 4.4948 - val_loss: 4.6198\n",
      "Epoch 2/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 4.4800 - val_loss: 4.6091\n",
      "Epoch 3/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 4.4692 - val_loss: 4.5995\n",
      "Epoch 4/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 4.4592 - val_loss: 4.5904\n",
      "Epoch 5/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 4.4506 - val_loss: 4.5833\n",
      "Epoch 6/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 4.4451 - val_loss: 4.5797\n",
      "Epoch 7/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 4.4421 - val_loss: 4.5767\n",
      "Epoch 8/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 4.4379 - val_loss: 4.5715\n",
      "Epoch 9/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 4.4309 - val_loss: 4.5635\n",
      "Epoch 10/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 4.4223 - val_loss: 4.5543\n",
      "Epoch 11/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 4.4131 - val_loss: 4.5445\n",
      "Epoch 12/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 4.4034 - val_loss: 4.5347\n",
      "Epoch 13/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 4.3928 - val_loss: 4.5237\n",
      "Epoch 14/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 4.3812 - val_loss: 4.5112\n",
      "Epoch 15/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 4.3682 - val_loss: 4.4973\n",
      "Epoch 16/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 4.3542 - val_loss: 4.4825\n",
      "Epoch 17/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 4.3386 - val_loss: 4.4658\n",
      "Epoch 18/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 4.3207 - val_loss: 4.4464\n",
      "Epoch 19/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 4.3005 - val_loss: 4.4249\n",
      "Epoch 20/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 4.2776 - val_loss: 4.4002\n",
      "Epoch 21/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 4.2520 - val_loss: 4.3729\n",
      "Epoch 22/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 4.2234 - val_loss: 4.3434\n",
      "Epoch 23/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 4.1916 - val_loss: 4.3106\n",
      "Epoch 24/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 4.1552 - val_loss: 4.2735\n",
      "Epoch 25/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 4.1132 - val_loss: 4.2304\n",
      "Epoch 26/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 4.0653 - val_loss: 4.1821\n",
      "Epoch 27/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 4.0106 - val_loss: 4.1268\n",
      "Epoch 28/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 3.9482 - val_loss: 4.0635\n",
      "Epoch 29/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 3.8761 - val_loss: 3.9901\n",
      "Epoch 30/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 3.7949 - val_loss: 3.9092\n",
      "Epoch 31/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 3.7096 - val_loss: 3.8303\n",
      "Epoch 32/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 3.6348 - val_loss: 3.7622\n",
      "Epoch 33/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 3.5756 - val_loss: 3.7040\n",
      "Epoch 34/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 3.5240 - val_loss: 3.6480\n",
      "Epoch 35/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 3.4715 - val_loss: 3.5883\n",
      "Epoch 36/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 3.4166 - val_loss: 3.5240\n",
      "Epoch 37/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 3.3576 - val_loss: 3.4544\n",
      "Epoch 38/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 3.2949 - val_loss: 3.3786\n",
      "Epoch 39/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 3.2276 - val_loss: 3.3003\n",
      "Epoch 40/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 3.1551 - val_loss: 3.2159\n",
      "Epoch 41/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 3.0771 - val_loss: 3.1296\n",
      "Epoch 42/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 3.0021 - val_loss: 3.0372\n",
      "Epoch 43/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.9303 - val_loss: 2.9491\n",
      "Epoch 44/300\n",
      "247/247 [==============================] - 4s 14ms/step - loss: 2.8625 - val_loss: 2.8662\n",
      "Epoch 45/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.7998 - val_loss: 2.7729\n",
      "Epoch 46/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.7447 - val_loss: 2.7047\n",
      "Epoch 47/300\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 2.7014 - val_loss: 2.6538\n",
      "Epoch 48/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.6652 - val_loss: 2.6068\n",
      "Epoch 49/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.6336 - val_loss: 2.5691\n",
      "Epoch 50/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.6095 - val_loss: 2.5312\n",
      "Epoch 51/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.5865 - val_loss: 2.4930\n",
      "Epoch 52/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.5659 - val_loss: 2.4645\n",
      "Epoch 53/300\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 2.5512 - val_loss: 2.4469\n",
      "Epoch 54/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.5397 - val_loss: 2.4241\n",
      "Epoch 55/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.5294 - val_loss: 2.4088\n",
      "Epoch 56/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.5202 - val_loss: 2.3976\n",
      "Epoch 57/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.5137 - val_loss: 2.3846\n",
      "Epoch 58/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.5095 - val_loss: 2.3768\n",
      "Epoch 59/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.5055 - val_loss: 2.3730\n",
      "Epoch 60/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.5033 - val_loss: 2.3679\n",
      "Epoch 61/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.5012 - val_loss: 2.3625\n",
      "Epoch 62/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4992 - val_loss: 2.3585\n",
      "Epoch 63/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4973 - val_loss: 2.3545\n",
      "Epoch 64/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4961 - val_loss: 2.3499\n",
      "Epoch 65/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4943 - val_loss: 2.3455\n",
      "Epoch 66/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4927 - val_loss: 2.3424\n",
      "Epoch 67/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4914 - val_loss: 2.3394\n",
      "Epoch 68/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4901 - val_loss: 2.3361\n",
      "Epoch 69/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4884 - val_loss: 2.3329\n",
      "Epoch 70/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4871 - val_loss: 2.3315\n",
      "Epoch 71/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4870 - val_loss: 2.3268\n",
      "Epoch 72/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4849 - val_loss: 2.3259\n",
      "Epoch 73/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4837 - val_loss: 2.3226\n",
      "Epoch 74/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4823 - val_loss: 2.3191\n",
      "Epoch 75/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4813 - val_loss: 2.3152\n",
      "Epoch 76/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4805 - val_loss: 2.3140\n",
      "Epoch 77/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4785 - val_loss: 2.3101\n",
      "Epoch 78/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4774 - val_loss: 2.3083\n",
      "Epoch 79/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4763 - val_loss: 2.3037\n",
      "Epoch 80/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4748 - val_loss: 2.3031\n",
      "Epoch 81/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4739 - val_loss: 2.2999\n",
      "Epoch 82/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4726 - val_loss: 2.2964\n",
      "Epoch 83/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4712 - val_loss: 2.2968\n",
      "Epoch 84/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4706 - val_loss: 2.2953\n",
      "Epoch 85/300\n",
      "247/247 [==============================] - 3s 13ms/step - loss: 2.4695 - val_loss: 2.2915\n",
      "Epoch 86/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4684 - val_loss: 2.2903\n",
      "Epoch 87/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4678 - val_loss: 2.2900\n",
      "Epoch 88/300\n",
      "247/247 [==============================] - 3s 13ms/step - loss: 2.4672 - val_loss: 2.2884\n",
      "Epoch 89/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4660 - val_loss: 2.2882\n",
      "Epoch 90/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4653 - val_loss: 2.2871\n",
      "Epoch 91/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4649 - val_loss: 2.2844\n",
      "Epoch 92/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4636 - val_loss: 2.2831\n",
      "Epoch 93/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.4632 - val_loss: 2.2829\n",
      "Epoch 94/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4626 - val_loss: 2.2802\n",
      "Epoch 95/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.4614 - val_loss: 2.2836\n",
      "Epoch 96/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.4610 - val_loss: 2.2804\n",
      "Epoch 97/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.4600 - val_loss: 2.2804\n",
      "Epoch 98/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4594 - val_loss: 2.2776\n",
      "Epoch 99/300\n",
      "247/247 [==============================] - 4s 14ms/step - loss: 2.4583 - val_loss: 2.2769\n",
      "Epoch 100/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4583 - val_loss: 2.2746\n",
      "Epoch 101/300\n",
      "247/247 [==============================] - 4s 14ms/step - loss: 2.4572 - val_loss: 2.2732\n",
      "Epoch 102/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4561 - val_loss: 2.2727\n",
      "Epoch 103/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.4555 - val_loss: 2.2693\n",
      "Epoch 104/300\n",
      "247/247 [==============================] - 3s 13ms/step - loss: 2.4545 - val_loss: 2.2700\n",
      "Epoch 105/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4551 - val_loss: 2.2704\n",
      "Epoch 106/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4536 - val_loss: 2.2668\n",
      "Epoch 107/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4526 - val_loss: 2.2649\n",
      "Epoch 108/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4521 - val_loss: 2.2654\n",
      "Epoch 109/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4507 - val_loss: 2.2637\n",
      "Epoch 110/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4504 - val_loss: 2.2636\n",
      "Epoch 111/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4498 - val_loss: 2.2608\n",
      "Epoch 112/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4485 - val_loss: 2.2620\n",
      "Epoch 113/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4485 - val_loss: 2.2591\n",
      "Epoch 114/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4474 - val_loss: 2.2585\n",
      "Epoch 115/300\n",
      "247/247 [==============================] - 4s 16ms/step - loss: 2.4464 - val_loss: 2.2573\n",
      "Epoch 116/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4456 - val_loss: 2.2574\n",
      "Epoch 117/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4448 - val_loss: 2.2545\n",
      "Epoch 118/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4443 - val_loss: 2.2538\n",
      "Epoch 119/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4428 - val_loss: 2.2534\n",
      "Epoch 120/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.4429 - val_loss: 2.2523\n",
      "Epoch 121/300\n",
      "247/247 [==============================] - 3s 13ms/step - loss: 2.4423 - val_loss: 2.2513\n",
      "Epoch 122/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4407 - val_loss: 2.2486\n",
      "Epoch 123/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4400 - val_loss: 2.2495\n",
      "Epoch 124/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4400 - val_loss: 2.2476\n",
      "Epoch 125/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4383 - val_loss: 2.2475\n",
      "Epoch 126/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4381 - val_loss: 2.2448\n",
      "Epoch 127/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4384 - val_loss: 2.2436\n",
      "Epoch 128/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4361 - val_loss: 2.2440\n",
      "Epoch 129/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.4355 - val_loss: 2.2416\n",
      "Epoch 130/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4350 - val_loss: 2.2404\n",
      "Epoch 131/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.4350 - val_loss: 2.2399\n",
      "Epoch 132/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4337 - val_loss: 2.2401\n",
      "Epoch 133/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4337 - val_loss: 2.2374\n",
      "Epoch 134/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4321 - val_loss: 2.2371\n",
      "Epoch 135/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4317 - val_loss: 2.2363\n",
      "Epoch 136/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4308 - val_loss: 2.2349\n",
      "Epoch 137/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4302 - val_loss: 2.2350\n",
      "Epoch 138/300\n",
      "247/247 [==============================] - 3s 14ms/step - loss: 2.4292 - val_loss: 2.2352\n",
      "Epoch 139/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.4282 - val_loss: 2.2318\n",
      "Epoch 140/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.4283 - val_loss: 2.2303\n",
      "Epoch 141/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4265 - val_loss: 2.2324\n",
      "Epoch 142/300\n",
      "247/247 [==============================] - 3s 14ms/step - loss: 2.4265 - val_loss: 2.2288\n",
      "Epoch 143/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4253 - val_loss: 2.2273\n",
      "Epoch 144/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4240 - val_loss: 2.2270\n",
      "Epoch 145/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4242 - val_loss: 2.2271\n",
      "Epoch 146/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4236 - val_loss: 2.2257\n",
      "Epoch 147/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4235 - val_loss: 2.2219\n",
      "Epoch 148/300\n",
      "247/247 [==============================] - 5s 19ms/step - loss: 2.4225 - val_loss: 2.2210\n",
      "Epoch 149/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.4215 - val_loss: 2.2200\n",
      "Epoch 150/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4200 - val_loss: 2.2201\n",
      "Epoch 151/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4190 - val_loss: 2.2179\n",
      "Epoch 152/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4190 - val_loss: 2.2182\n",
      "Epoch 153/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4175 - val_loss: 2.2166\n",
      "Epoch 154/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4168 - val_loss: 2.2174\n",
      "Epoch 155/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4162 - val_loss: 2.2147\n",
      "Epoch 156/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.4153 - val_loss: 2.2125\n",
      "Epoch 157/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4147 - val_loss: 2.2107\n",
      "Epoch 158/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4150 - val_loss: 2.2113\n",
      "Epoch 159/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.4129 - val_loss: 2.2076\n",
      "Epoch 160/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.4125 - val_loss: 2.2068\n",
      "Epoch 161/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4112 - val_loss: 2.2040\n",
      "Epoch 162/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.4105 - val_loss: 2.2039\n",
      "Epoch 163/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4099 - val_loss: 2.2011\n",
      "Epoch 164/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4090 - val_loss: 2.1992\n",
      "Epoch 165/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4081 - val_loss: 2.1986\n",
      "Epoch 166/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4081 - val_loss: 2.1994\n",
      "Epoch 167/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4071 - val_loss: 2.1980\n",
      "Epoch 168/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4063 - val_loss: 2.1970\n",
      "Epoch 169/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4059 - val_loss: 2.1962\n",
      "Epoch 170/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4053 - val_loss: 2.1934\n",
      "Epoch 171/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.4041 - val_loss: 2.1964\n",
      "Epoch 172/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4030 - val_loss: 2.1923\n",
      "Epoch 173/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.4034 - val_loss: 2.1916\n",
      "Epoch 174/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.4025 - val_loss: 2.1908\n",
      "Epoch 175/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.4018 - val_loss: 2.1896\n",
      "Epoch 176/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4009 - val_loss: 2.1900\n",
      "Epoch 177/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.4003 - val_loss: 2.1859\n",
      "Epoch 178/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3995 - val_loss: 2.1856\n",
      "Epoch 179/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.3986 - val_loss: 2.1847\n",
      "Epoch 180/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3983 - val_loss: 2.1825\n",
      "Epoch 181/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3973 - val_loss: 2.1820\n",
      "Epoch 182/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.3969 - val_loss: 2.1814\n",
      "Epoch 183/300\n",
      "247/247 [==============================] - 3s 14ms/step - loss: 2.3958 - val_loss: 2.1788\n",
      "Epoch 184/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3953 - val_loss: 2.1802\n",
      "Epoch 185/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3943 - val_loss: 2.1789\n",
      "Epoch 186/300\n",
      "247/247 [==============================] - 4s 14ms/step - loss: 2.3934 - val_loss: 2.1793\n",
      "Epoch 187/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3930 - val_loss: 2.1784\n",
      "Epoch 188/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3924 - val_loss: 2.1765\n",
      "Epoch 189/300\n",
      "247/247 [==============================] - 3s 14ms/step - loss: 2.3915 - val_loss: 2.1747\n",
      "Epoch 190/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3912 - val_loss: 2.1726\n",
      "Epoch 191/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3898 - val_loss: 2.1716\n",
      "Epoch 192/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3898 - val_loss: 2.1703\n",
      "Epoch 193/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3885 - val_loss: 2.1699\n",
      "Epoch 194/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3876 - val_loss: 2.1683\n",
      "Epoch 195/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.3876 - val_loss: 2.1679\n",
      "Epoch 196/300\n",
      "247/247 [==============================] - 3s 13ms/step - loss: 2.3861 - val_loss: 2.1700\n",
      "Epoch 197/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.3859 - val_loss: 2.1660\n",
      "Epoch 198/300\n",
      "247/247 [==============================] - 3s 13ms/step - loss: 2.3855 - val_loss: 2.1676\n",
      "Epoch 199/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3841 - val_loss: 2.1628\n",
      "Epoch 200/300\n",
      "247/247 [==============================] - 3s 13ms/step - loss: 2.3831 - val_loss: 2.1629\n",
      "Epoch 201/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3833 - val_loss: 2.1608\n",
      "Epoch 202/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.3815 - val_loss: 2.1592\n",
      "Epoch 203/300\n",
      "247/247 [==============================] - 3s 13ms/step - loss: 2.3815 - val_loss: 2.1597\n",
      "Epoch 204/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.3801 - val_loss: 2.1573\n",
      "Epoch 205/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3791 - val_loss: 2.1579\n",
      "Epoch 206/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3788 - val_loss: 2.1561\n",
      "Epoch 207/300\n",
      "247/247 [==============================] - 3s 14ms/step - loss: 2.3778 - val_loss: 2.1552\n",
      "Epoch 208/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.3778 - val_loss: 2.1528\n",
      "Epoch 209/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.3772 - val_loss: 2.1512\n",
      "Epoch 210/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3761 - val_loss: 2.1532\n",
      "Epoch 211/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.3751 - val_loss: 2.1527\n",
      "Epoch 212/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3747 - val_loss: 2.1518\n",
      "Epoch 213/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.3743 - val_loss: 2.1516\n",
      "Epoch 214/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3736 - val_loss: 2.1491\n",
      "Epoch 215/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.3735 - val_loss: 2.1499\n",
      "Epoch 216/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3720 - val_loss: 2.1504\n",
      "Epoch 217/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3708 - val_loss: 2.1485\n",
      "Epoch 218/300\n",
      "247/247 [==============================] - 3s 14ms/step - loss: 2.3710 - val_loss: 2.1459\n",
      "Epoch 219/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3703 - val_loss: 2.1473\n",
      "Epoch 220/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.3708 - val_loss: 2.1459\n",
      "Epoch 221/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3688 - val_loss: 2.1440\n",
      "Epoch 222/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3683 - val_loss: 2.1434\n",
      "Epoch 223/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3679 - val_loss: 2.1424\n",
      "Epoch 224/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3664 - val_loss: 2.1448\n",
      "Epoch 225/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.3668 - val_loss: 2.1448\n",
      "Epoch 226/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3656 - val_loss: 2.1438\n",
      "Epoch 227/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.3653 - val_loss: 2.1424\n",
      "Epoch 228/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3642 - val_loss: 2.1426\n",
      "Epoch 229/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3637 - val_loss: 2.1427\n",
      "Epoch 230/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3630 - val_loss: 2.1405\n",
      "Epoch 231/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3617 - val_loss: 2.1416\n",
      "Epoch 232/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3612 - val_loss: 2.1403\n",
      "Epoch 233/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3610 - val_loss: 2.1381\n",
      "Epoch 234/300\n",
      "247/247 [==============================] - 3s 13ms/step - loss: 2.3605 - val_loss: 2.1400\n",
      "Epoch 235/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3592 - val_loss: 2.1386\n",
      "Epoch 236/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.3594 - val_loss: 2.1378\n",
      "Epoch 237/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.3588 - val_loss: 2.1359\n",
      "Epoch 238/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.3577 - val_loss: 2.1358\n",
      "Epoch 239/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.3576 - val_loss: 2.1371\n",
      "Epoch 240/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.3563 - val_loss: 2.1360\n",
      "Epoch 241/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3557 - val_loss: 2.1346\n",
      "Epoch 242/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.3547 - val_loss: 2.1353\n",
      "Epoch 243/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3542 - val_loss: 2.1345\n",
      "Epoch 244/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.3538 - val_loss: 2.1334\n",
      "Epoch 245/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.3530 - val_loss: 2.1338\n",
      "Epoch 246/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.3519 - val_loss: 2.1330\n",
      "Epoch 247/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3513 - val_loss: 2.1327\n",
      "Epoch 248/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3512 - val_loss: 2.1336\n",
      "Epoch 249/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3505 - val_loss: 2.1299\n",
      "Epoch 250/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3492 - val_loss: 2.1332\n",
      "Epoch 251/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3492 - val_loss: 2.1309\n",
      "Epoch 252/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.3481 - val_loss: 2.1303\n",
      "Epoch 253/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3475 - val_loss: 2.1304\n",
      "Epoch 254/300\n",
      "247/247 [==============================] - 3s 13ms/step - loss: 2.3461 - val_loss: 2.1300\n",
      "Epoch 255/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3459 - val_loss: 2.1284\n",
      "Epoch 256/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.3453 - val_loss: 2.1282\n",
      "Epoch 257/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.3454 - val_loss: 2.1270\n",
      "Epoch 258/300\n",
      "247/247 [==============================] - 4s 14ms/step - loss: 2.3440 - val_loss: 2.1273\n",
      "Epoch 259/300\n",
      "247/247 [==============================] - 3s 13ms/step - loss: 2.3432 - val_loss: 2.1247\n",
      "Epoch 260/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3426 - val_loss: 2.1257\n",
      "Epoch 261/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3422 - val_loss: 2.1247\n",
      "Epoch 262/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3410 - val_loss: 2.1249\n",
      "Epoch 263/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3405 - val_loss: 2.1236\n",
      "Epoch 264/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3405 - val_loss: 2.1210\n",
      "Epoch 265/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3390 - val_loss: 2.1202\n",
      "Epoch 266/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3378 - val_loss: 2.1209\n",
      "Epoch 267/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3367 - val_loss: 2.1227\n",
      "Epoch 268/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3366 - val_loss: 2.1173\n",
      "Epoch 269/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3359 - val_loss: 2.1163\n",
      "Epoch 270/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3351 - val_loss: 2.1171\n",
      "Epoch 271/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3349 - val_loss: 2.1130\n",
      "Epoch 272/300\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 2.3332 - val_loss: 2.1146\n",
      "Epoch 273/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3331 - val_loss: 2.1125\n",
      "Epoch 274/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3318 - val_loss: 2.1108\n",
      "Epoch 275/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3317 - val_loss: 2.1108\n",
      "Epoch 276/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3306 - val_loss: 2.1124\n",
      "Epoch 277/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3302 - val_loss: 2.1112\n",
      "Epoch 278/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3298 - val_loss: 2.1119\n",
      "Epoch 279/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.3289 - val_loss: 2.1082\n",
      "Epoch 280/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3271 - val_loss: 2.1082\n",
      "Epoch 281/300\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 2.3270 - val_loss: 2.1073\n",
      "Epoch 282/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3268 - val_loss: 2.1069\n",
      "Epoch 283/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.3258 - val_loss: 2.1054\n",
      "Epoch 284/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.3246 - val_loss: 2.1066\n",
      "Epoch 285/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.3244 - val_loss: 2.1054\n",
      "Epoch 286/300\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 2.3231 - val_loss: 2.1072\n",
      "Epoch 287/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3230 - val_loss: 2.1048\n",
      "Epoch 288/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3219 - val_loss: 2.1055\n",
      "Epoch 289/300\n",
      "247/247 [==============================] - 3s 12ms/step - loss: 2.3216 - val_loss: 2.1046\n",
      "Epoch 290/300\n",
      "247/247 [==============================] - 2s 8ms/step - loss: 2.3207 - val_loss: 2.1041\n",
      "Epoch 291/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3203 - val_loss: 2.1062\n",
      "Epoch 292/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3188 - val_loss: 2.1042\n",
      "Epoch 293/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3189 - val_loss: 2.1032\n",
      "Epoch 294/300\n",
      "247/247 [==============================] - 3s 13ms/step - loss: 2.3182 - val_loss: 2.1021\n",
      "Epoch 295/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3169 - val_loss: 2.1042\n",
      "Epoch 296/300\n",
      "247/247 [==============================] - 3s 10ms/step - loss: 2.3172 - val_loss: 2.1014\n",
      "Epoch 297/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3162 - val_loss: 2.1027\n",
      "Epoch 298/300\n",
      "247/247 [==============================] - 2s 10ms/step - loss: 2.3151 - val_loss: 2.1033\n",
      "Epoch 299/300\n",
      "247/247 [==============================] - 2s 9ms/step - loss: 2.3140 - val_loss: 2.1007\n",
      "Epoch 300/300\n",
      "247/247 [==============================] - 3s 11ms/step - loss: 2.3134 - val_loss: 2.0997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x168b06474c0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = nanozymes_synthesis()\n",
    "ns.load('peroxidase.xlsx',\n",
    "        'nanozymes_add.xlsx',\n",
    "        'nanozymes_formulas.xlsx',\n",
    "        'reaction_types.xlsx',\n",
    "        'Rs.xlsx',\n",
    "        'solvents.xlsx',\n",
    "        'solvents_add.xlsx'\n",
    "       )\n",
    "ns.preprocessing()\n",
    "ns.train(1e-4, 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5733dc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ns.plot_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613e0bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved\\assets\n"
     ]
    }
   ],
   "source": [
    "ns.model_save('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4d01a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns.model_load('saved', 'x_scaler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96962edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns.model_save('modfel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f88862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
